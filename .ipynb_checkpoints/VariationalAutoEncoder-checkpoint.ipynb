{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ca59bdf9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T14:35:11.053244Z",
     "start_time": "2024-12-07T14:35:11.049238Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "bf5834b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T14:35:11.419186Z",
     "start_time": "2024-12-07T14:35:11.411346Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual device: mps\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "    \n",
    "print(f'Actual device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "7647be8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T14:35:11.809883Z",
     "start_time": "2024-12-07T14:35:11.799559Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22222222, 0.625     , 0.06779661, 0.04166667],\n",
       "       [0.16666667, 0.41666667, 0.06779661, 0.04166667],\n",
       "       [0.11111111, 0.5       , 0.05084746, 0.04166667],\n",
       "       [0.08333333, 0.45833333, 0.08474576, 0.04166667],\n",
       "       [0.19444444, 0.66666667, 0.06779661, 0.04166667],\n",
       "       [0.30555556, 0.79166667, 0.11864407, 0.125     ],\n",
       "       [0.08333333, 0.58333333, 0.06779661, 0.08333333],\n",
       "       [0.19444444, 0.58333333, 0.08474576, 0.04166667],\n",
       "       [0.02777778, 0.375     , 0.06779661, 0.04166667],\n",
       "       [0.16666667, 0.45833333, 0.08474576, 0.        ]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = load_iris()['data']\n",
    "X\n",
    "min_max = MinMaxScaler()\n",
    "#std_scl = StandardScaler()\n",
    "X = min_max.fit_transform(X)\n",
    "#X = std_scl.fit_transform(X)\n",
    "X[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b083ac9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T14:35:12.354271Z",
     "start_time": "2024-12-07T14:35:12.345418Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4])\n",
      "tensor([[0.4167, 0.8333, 0.0339, 0.0417],\n",
      "        [0.3056, 0.7083, 0.0847, 0.0417],\n",
      "        [0.3611, 0.3750, 0.4407, 0.5000],\n",
      "        [0.3056, 0.5833, 0.0847, 0.1250],\n",
      "        [0.5000, 0.3333, 0.6271, 0.4583],\n",
      "        [0.1667, 0.2083, 0.5932, 0.6667],\n",
      "        [0.2222, 0.2083, 0.3390, 0.4167],\n",
      "        [0.0000, 0.4167, 0.0169, 0.0000],\n",
      "        [0.4722, 0.0833, 0.6780, 0.5833],\n",
      "        [0.6111, 0.4167, 0.7627, 0.7083],\n",
      "        [0.1944, 0.1250, 0.3898, 0.3750],\n",
      "        [0.4167, 0.2917, 0.4915, 0.4583],\n",
      "        [0.7778, 0.4167, 0.8305, 0.8333],\n",
      "        [0.1944, 0.5833, 0.0847, 0.0417],\n",
      "        [0.5278, 0.3333, 0.6441, 0.7083],\n",
      "        [0.5833, 0.3750, 0.5593, 0.5000],\n",
      "        [0.6667, 0.4167, 0.6780, 0.6667],\n",
      "        [0.9167, 0.4167, 0.9492, 0.8333],\n",
      "        [0.4167, 0.3333, 0.6949, 0.9583],\n",
      "        [0.2500, 0.2917, 0.4915, 0.5417],\n",
      "        [0.5556, 0.2083, 0.6610, 0.5833],\n",
      "        [0.3056, 0.7917, 0.1186, 0.1250],\n",
      "        [0.5833, 0.5000, 0.7288, 0.9167],\n",
      "        [0.0278, 0.4167, 0.0508, 0.0417],\n",
      "        [0.3333, 0.6250, 0.0508, 0.0417],\n",
      "        [0.4722, 0.3750, 0.5932, 0.5833],\n",
      "        [0.9444, 0.7500, 0.9661, 0.8750],\n",
      "        [0.1944, 0.6667, 0.0678, 0.0417],\n",
      "        [0.8333, 0.3750, 0.8983, 0.7083],\n",
      "        [0.1111, 0.5000, 0.0508, 0.0417],\n",
      "        [0.8056, 0.4167, 0.8136, 0.6250],\n",
      "        [0.3889, 0.3333, 0.5932, 0.5000]])\n"
     ]
    }
   ],
   "source": [
    "class IrisDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = torch.tensor(data, dtype = torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "dataset = IrisDataset(X)\n",
    "dataloader = DataLoader(dataset, batch_size = 32, shuffle = True)\n",
    "\n",
    "for batch in dataloader:\n",
    "    print(f'{batch.shape}\\n{batch}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "5fecc5c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T14:35:15.778536Z",
     "start_time": "2024-12-07T14:35:15.774158Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in dataloader:\n",
    "    batch = i\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "370c1312",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T14:41:56.254271Z",
     "start_time": "2024-12-07T14:41:56.224943Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.3996, -0.0539, -0.0260,  0.0943],\n",
       "         [ 0.1689, -0.1291,  0.0132, -0.0819],\n",
       "         [ 0.2273, -0.1118, -0.0586, -0.0346],\n",
       "         [ 0.2408, -0.1092, -0.0404, -0.0197],\n",
       "         [ 0.1696, -0.1284,  0.0143, -0.0814],\n",
       "         [ 0.3756, -0.0614, -0.1363,  0.0705],\n",
       "         [ 0.1691, -0.1289,  0.0136, -0.0817],\n",
       "         [ 0.2269, -0.1095, -0.1506, -0.0449],\n",
       "         [ 0.2839, -0.1001,  0.1769,  0.0354],\n",
       "         [ 0.2219, -0.1116, -0.0557, -0.0443],\n",
       "         [ 0.1691, -0.1289,  0.0135, -0.0818],\n",
       "         [ 0.2342, -0.1076, -0.1754, -0.0403],\n",
       "         [ 0.2572, -0.1029, -0.1068, -0.0115],\n",
       "         [ 0.2083, -0.1160,  0.0398, -0.0503],\n",
       "         [ 0.2621, -0.0988, -0.2171, -0.0188],\n",
       "         [ 0.2627, -0.1018, -0.0945, -0.0049],\n",
       "         [ 0.2483, -0.1121,  0.2666,  0.0118],\n",
       "         [ 0.1689, -0.1291,  0.0132, -0.0819],\n",
       "         [ 0.3482, -0.0709,  0.1320,  0.0620],\n",
       "         [ 0.2410, -0.1136,  0.2531,  0.0046],\n",
       "         [ 0.2341, -0.1101, -0.0737, -0.0295],\n",
       "         [ 0.2319, -0.1078, -0.1649, -0.0418],\n",
       "         [ 0.3161, -0.0897,  0.1839,  0.0602],\n",
       "         [ 0.1690, -0.1290,  0.0135, -0.0818],\n",
       "         [ 0.2394, -0.1092, -0.0526, -0.0223],\n",
       "         [ 0.3293, -0.0850,  0.0659,  0.0640],\n",
       "         [ 0.2512, -0.1014, -0.2207, -0.0294],\n",
       "         [ 0.1692, -0.1288,  0.0137, -0.0817],\n",
       "         [ 0.3302, -0.0844,  0.0678,  0.0649],\n",
       "         [ 0.1689, -0.1291,  0.0132, -0.0819],\n",
       "         [ 0.3111, -0.0829,  0.1075,  0.0322],\n",
       "         [ 0.1696, -0.1284,  0.0143, -0.0814]], grad_fn=<AddmmBackward0>),\n",
       " tensor([[-0.5104,  0.0042,  0.3227, -0.5104],\n",
       "         [-0.4220,  0.2301,  0.1275, -0.4606],\n",
       "         [-0.5052,  0.1401,  0.2422, -0.4283],\n",
       "         [-0.4954,  0.1185,  0.2557, -0.4433],\n",
       "         [-0.4210,  0.2299,  0.1275, -0.4618],\n",
       "         [-0.6040,  0.0032,  0.3775, -0.4269],\n",
       "         [-0.4217,  0.2300,  0.1275, -0.4610],\n",
       "         [-0.5824,  0.1406,  0.2777, -0.3678],\n",
       "         [-0.3209,  0.0839,  0.1950, -0.6011],\n",
       "         [-0.4962,  0.1654,  0.2117, -0.4310],\n",
       "         [-0.4217,  0.2300,  0.1275, -0.4609],\n",
       "         [-0.6066,  0.1280,  0.2993, -0.3529],\n",
       "         [-0.5575,  0.0935,  0.3057, -0.4041],\n",
       "         [-0.4071,  0.1989,  0.1391, -0.4920],\n",
       "         [-0.6522,  0.0858,  0.3564, -0.3329],\n",
       "         [-0.5494,  0.0849,  0.3092, -0.4135],\n",
       "         [-0.2319,  0.1377,  0.1084, -0.6506],\n",
       "         [-0.4220,  0.2301,  0.1275, -0.4605],\n",
       "         [-0.3566,  0.0865,  0.1812, -0.6016],\n",
       "         [-0.2414,  0.1452,  0.1079, -0.6397],\n",
       "         [-0.5208,  0.1286,  0.2589, -0.4198],\n",
       "         [-0.5964,  0.1328,  0.2908, -0.3597],\n",
       "         [-0.3218,  0.0562,  0.2123, -0.6166],\n",
       "         [-0.4218,  0.2301,  0.1275, -0.4608],\n",
       "         [-0.5051,  0.1206,  0.2584, -0.4350],\n",
       "         [-0.4301,  0.0214,  0.2956, -0.5405],\n",
       "         [-0.6510,  0.1026,  0.3416, -0.3279],\n",
       "         [-0.4216,  0.2300,  0.1275, -0.4611],\n",
       "         [-0.4286,  0.0207,  0.2958, -0.5422],\n",
       "         [-0.4220,  0.2301,  0.1275, -0.4606],\n",
       "         [-0.3700,  0.1163,  0.1701, -0.5725],\n",
       "         [-0.4210,  0.2299,  0.1275, -0.4618]], grad_fn=<AddmmBackward0>),\n",
       " tensor([[-0.2221,  0.1049, -0.3905, -0.2022],\n",
       "         [-0.1812,  0.2195, -0.0904, -0.0975],\n",
       "         [-0.2488,  0.2883, -0.1139, -0.2149],\n",
       "         [-0.2607,  0.1347,  0.0377, -0.0816],\n",
       "         [-0.2488,  0.3383, -0.0072,  0.0967],\n",
       "         [-0.2880,  0.2148, -0.0203,  0.0267],\n",
       "         [-0.2497,  0.1629, -0.0726, -0.1436],\n",
       "         [-0.3086,  0.0389, -0.1728, -0.4557],\n",
       "         [-0.1475,  0.1971, -0.2731, -0.1721],\n",
       "         [-0.2128,  0.1665, -0.0836, -0.2225],\n",
       "         [-0.2026,  0.2513, -0.2852, -0.1216],\n",
       "         [-0.4246,  0.1058,  0.1200, -0.2367],\n",
       "         [-0.4287,  0.1080,  0.1233, -0.0072],\n",
       "         [-0.2796,  0.3220, -0.0296,  0.1491],\n",
       "         [-0.4534,  0.2415,  0.0522, -0.1566],\n",
       "         [-0.2225,  0.1681,  0.0380, -0.1111],\n",
       "         [-0.4527,  0.1781, -0.0010, -0.2469],\n",
       "         [-0.0551,  0.1738, -0.2552, -0.0193],\n",
       "         [-0.0774, -0.1627, -0.0765, -0.3292],\n",
       "         [-0.2598,  0.0906,  0.1181, -0.2382],\n",
       "         [-0.3307,  0.2568,  0.1362, -0.2196],\n",
       "         [-0.6148,  0.2983,  0.4904, -0.0641],\n",
       "         [-0.2083,  0.2000,  0.0049, -0.0576],\n",
       "         [-0.3170,  0.2741, -0.0092, -0.3546],\n",
       "         [-0.4900,  0.2664,  0.0081,  0.0277],\n",
       "         [-0.2543,  0.0288, -0.0621, -0.1970],\n",
       "         [-0.2366,  0.2377,  0.0924, -0.1577],\n",
       "         [-0.3056,  0.2224,  0.0121, -0.1324],\n",
       "         [-0.1596,  0.2310, -0.5353, -0.1450],\n",
       "         [-0.5772,  0.4155, -0.0918, -0.1419],\n",
       "         [-0.3868, -0.0405,  0.1454,  0.1018],\n",
       "         [-0.1442,  0.2021, -0.1011, -0.0404]], grad_fn=<TanhBackward0>))"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VariationalAutoEncoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_dim = 4, \n",
    "                 layers = 5,\n",
    "                 dropout_rate = 0.5,\n",
    "                 latent_space_dim = 2):\n",
    "        super(VariationalAutoEncoder, self).__init__()\n",
    "        \n",
    "        max_neurons = 2 ** layers\n",
    "\n",
    "        encoder_layers_list = [\n",
    "            nn.Linear(input_dim, max_neurons),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        ]\n",
    "        \n",
    "        current_dim = max_neurons\n",
    "        while current_dim > latent_space_dim:\n",
    "            next_dim = current_dim // 2\n",
    "            encoder_layers_list.extend(nn.Sequential(\n",
    "                nn.Linear(current_dim, next_dim),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Dropout(dropout_rate)\n",
    "            ))\n",
    "            current_dim = next_dim\n",
    "        \n",
    "        encoder_layers_list.append(nn.Linear(current_dim, latent_space_dim))\n",
    "\n",
    "        self.Encoder = nn.Sequential(*encoder_layers_list)\n",
    "        \n",
    "        self.fc_mu = nn.Linear(next_dim, latent_space_dim)\n",
    "        self.fc_logvar = nn.Linear(next_dim, latent_space_dim)\n",
    "        \n",
    "        decoder_layers_list = []\n",
    "        current_dim = latent_space_dim\n",
    "        while current_dim < max_neurons:\n",
    "            next_dim = current_dim * 2\n",
    "            decoder_layers_list.extend([\n",
    "                nn.Linear(current_dim, next_dim),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Dropout(dropout_rate)\n",
    "            ])\n",
    "            current_dim = next_dim\n",
    "        \n",
    "        # L'ultimo strato del decoder per ricostruire l'input\n",
    "        decoder_layers_list.append(nn.Linear(current_dim, input_dim))\n",
    "        decoder_layers_list.append(nn.Tanh())\n",
    "        \n",
    "        self.Decoder = nn.Sequential(*decoder_layers_list)\n",
    "        \n",
    "        \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        \"\"\"\n",
    "        Implementa il trick della rielaborazione per campionare dallo spazio latente.\n",
    "        Args:\n",
    "            mu (torch.Tensor): Media della distribuzione latente (dimensione: batch_size x latent_dim).\n",
    "            logvar (torch.Tensor): Log-varianza della distribuzione latente (dimensione: batch_size x latent_dim).\n",
    "        Returns:\n",
    "            z (torch.Tensor): Campione dallo spazio latente (dimensione: batch_size x latent_dim).\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5 * logvar)  # Calcola lo scarto quadratico medio\n",
    "        epsilon = torch.randn_like(std)  # Campiona da una distribuzione normale standard\n",
    "        z = mu + epsilon * std  # Applica il trick della rielaborazione\n",
    "        return z\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.Encoder(x)\n",
    "        mu, log_var = self.fc_mu(x), self.fc_logvar(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        reconstruction = self.Decoder(z)\n",
    "        \n",
    "        return mu, log_var, reconstruction\n",
    "        \n",
    "        \n",
    "vae = VariationalAutoEncoder(latent_space_dim = 4)\n",
    "vae\n",
    "vae(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "b073b856",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T14:41:56.721199Z",
     "start_time": "2024-12-07T14:41:56.715999Z"
    }
   },
   "outputs": [],
   "source": [
    "lr = 1e-5\n",
    "\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    # Perdita di ricostruzione (Errore quadratico medio)\n",
    "    reconstruction_loss = F.mse_loss(recon_x, x, reduction='sum')\n",
    "    \n",
    "    # Perdita di Divergenza KL\n",
    "    # Divari di distribuzioni (appena appreso vs. normale standard)\n",
    "    # Formula di KL: -0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    # dove mu e sigma sono la media e la deviazione standard della distribuzione latente.\n",
    "    kl_divergence = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    \n",
    "    # Funzione di perdita totale\n",
    "    return reconstruction_loss + kl_divergence\n",
    "\n",
    "optimizer = optim.AdamW(vae.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d003b331",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T14:47:43.352493Z",
     "start_time": "2024-12-07T14:46:53.730548Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a409df2a6fd4bfb9d5b081de1afa916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1000/10000], Loss: 0.2902\n",
      "Epoch [2000/10000], Loss: 0.2875\n",
      "Epoch [3000/10000], Loss: 0.2788\n",
      "Epoch [4000/10000], Loss: 0.2904\n",
      "Epoch [5000/10000], Loss: 0.2785\n",
      "Epoch [6000/10000], Loss: 0.2739\n",
      "Epoch [7000/10000], Loss: 0.2843\n",
      "Epoch [8000/10000], Loss: 0.2857\n",
      "Epoch [9000/10000], Loss: 0.2739\n"
     ]
    }
   ],
   "source": [
    "epochs = 10000\n",
    "\n",
    "for epoch in tqdm(range(epochs), desc = 'Training'):\n",
    "    vae.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, data in enumerate(dataloader):\n",
    "        \n",
    "        data = data.float()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        mu, log_var, rec = vae(data)\n",
    "        loss = loss_function(rec, data, mu, log_var)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    avg_train_loss = train_loss / len(dataloader.dataset)\n",
    "    if epoch % 1000 == 0 and epoch != 0:\n",
    "        print(f'Epoch [{epoch}/{epochs}], Loss: {avg_train_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d7eedabd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T14:31:14.184512Z",
     "start_time": "2024-12-07T14:31:14.177198Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_iris()['data'][:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5351a832",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T14:31:20.526528Z",
     "start_time": "2024-12-07T14:31:20.517055Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.849788 , 3.056685 , 3.7667842, 1.2053581],\n",
       "       [5.836423 , 3.0582294, 3.7513149, 1.1970277],\n",
       "       [5.8478074, 3.0545444, 3.7679594, 1.209895 ],\n",
       "       [5.8513784, 3.055823 , 3.7738783, 1.2105346],\n",
       "       [5.8376656, 3.060751 , 3.742765 , 1.1895307],\n",
       "       [5.836784 , 3.058817 , 3.747321 , 1.1895347],\n",
       "       [5.8463125, 3.0536792, 3.7714396, 1.212753 ],\n",
       "       [5.8386292, 3.0603087, 3.7459495, 1.1889246],\n",
       "       [5.854311 , 3.0576048, 3.77677  , 1.2157733],\n",
       "       [5.8467636, 3.0550447, 3.7678192, 1.2060039],\n",
       "       [5.846452 , 3.0554574, 3.7659245, 1.2081906],\n",
       "       [5.835979 , 3.0589201, 3.743428 , 1.1902221],\n",
       "       [5.838807 , 3.058964 , 3.7507088, 1.1942899],\n",
       "       [5.8481655, 3.0545468, 3.769882 , 1.2113799],\n",
       "       [5.834735 , 3.058921 , 3.7400725, 1.1881965],\n",
       "       [5.8339596, 3.0579345, 3.7447019, 1.1913834],\n",
       "       [5.8468447, 3.0552444, 3.7678506, 1.2075266],\n",
       "       [5.839301 , 3.0588505, 3.7528656, 1.1946388],\n",
       "       [5.836112 , 3.0581193, 3.7465496, 1.193663 ],\n",
       "       [5.8461437, 3.055367 , 3.7609377, 1.2047269],\n",
       "       [5.8470087, 3.0553465, 3.7670114, 1.2053564],\n",
       "       [5.8356233, 3.0592163, 3.7457693, 1.1909155],\n",
       "       [5.832496 , 3.0589201, 3.7389019, 1.1872289],\n",
       "       [5.8398714, 3.059189 , 3.7527413, 1.1937584],\n",
       "       [5.836319 , 3.058052 , 3.7469287, 1.1939309],\n",
       "       [5.84744  , 3.0542169, 3.7688117, 1.2106872],\n",
       "       [5.8461914, 3.053597 , 3.7718306, 1.2127391],\n",
       "       [5.8375216, 3.0577612, 3.7546675, 1.1953169],\n",
       "       [5.845998 , 3.0554817, 3.7600117, 1.2037226],\n",
       "       [5.8487797, 3.054994 , 3.7699218, 1.2114671],\n",
       "       [5.8437552, 3.0583417, 3.7391825, 1.1872721],\n",
       "       [5.8334317, 3.0576901, 3.7476032, 1.1942745]], dtype=float32)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_scl.inverse_transform(vae(torch.randn(32,4))[2].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a65467",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca59bdf9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T10:00:59.875748Z",
     "start_time": "2024-12-09T10:00:58.159300Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf5834b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T10:01:00.640406Z",
     "start_time": "2024-12-09T10:01:00.596578Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual device: mps\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "    \n",
    "print(f'Actual device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7647be8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T10:01:01.346928Z",
     "start_time": "2024-12-09T10:01:01.331541Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22222222, 0.625     , 0.06779661, 0.04166667],\n",
       "       [0.16666667, 0.41666667, 0.06779661, 0.04166667],\n",
       "       [0.11111111, 0.5       , 0.05084746, 0.04166667],\n",
       "       [0.08333333, 0.45833333, 0.08474576, 0.04166667],\n",
       "       [0.19444444, 0.66666667, 0.06779661, 0.04166667],\n",
       "       [0.30555556, 0.79166667, 0.11864407, 0.125     ],\n",
       "       [0.08333333, 0.58333333, 0.06779661, 0.08333333],\n",
       "       [0.19444444, 0.58333333, 0.08474576, 0.04166667],\n",
       "       [0.02777778, 0.375     , 0.06779661, 0.04166667],\n",
       "       [0.16666667, 0.45833333, 0.08474576, 0.        ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = load_iris()['data']\n",
    "X\n",
    "min_max = MinMaxScaler()\n",
    "#std_scl = StandardScaler()\n",
    "X = min_max.fit_transform(X)\n",
    "#X = std_scl.fit_transform(X)\n",
    "X[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b083ac9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T10:01:01.979132Z",
     "start_time": "2024-12-09T10:01:01.938745Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4])\n",
      "tensor([[0.2500, 0.8750, 0.0847, 0.0000],\n",
      "        [0.8333, 0.3750, 0.8983, 0.7083],\n",
      "        [0.4167, 0.2500, 0.5085, 0.4583],\n",
      "        [0.3056, 0.5833, 0.1186, 0.0417],\n",
      "        [0.3056, 0.4167, 0.5932, 0.5833],\n",
      "        [0.3333, 0.9167, 0.0678, 0.0417],\n",
      "        [0.2778, 0.7083, 0.0847, 0.0417],\n",
      "        [0.5556, 0.1250, 0.5763, 0.5000],\n",
      "        [0.1111, 0.5000, 0.1017, 0.0417],\n",
      "        [0.3611, 0.4167, 0.5932, 0.5833],\n",
      "        [0.5833, 0.4583, 0.7627, 0.7083],\n",
      "        [0.2222, 0.7500, 0.0847, 0.0833],\n",
      "        [0.3889, 0.3750, 0.5424, 0.5000],\n",
      "        [0.8611, 0.3333, 0.8644, 0.7500],\n",
      "        [0.4444, 0.4167, 0.5424, 0.5833],\n",
      "        [0.6667, 0.4583, 0.7797, 0.9583],\n",
      "        [0.1389, 0.5833, 0.1017, 0.0417],\n",
      "        [0.5556, 0.2083, 0.6610, 0.5833],\n",
      "        [0.6667, 0.4167, 0.7119, 0.9167],\n",
      "        [0.4722, 0.3750, 0.5932, 0.5833],\n",
      "        [0.0833, 0.6667, 0.0000, 0.0417],\n",
      "        [0.4722, 0.5833, 0.5932, 0.6250],\n",
      "        [0.1111, 0.5000, 0.0508, 0.0417],\n",
      "        [1.0000, 0.7500, 0.9153, 0.7917],\n",
      "        [0.0278, 0.3750, 0.0678, 0.0417],\n",
      "        [0.6667, 0.4583, 0.6271, 0.5833],\n",
      "        [0.5278, 0.0833, 0.5932, 0.5833],\n",
      "        [0.3889, 1.0000, 0.0847, 0.1250],\n",
      "        [0.3611, 0.2083, 0.4915, 0.4167],\n",
      "        [0.5000, 0.3333, 0.5085, 0.5000],\n",
      "        [0.1944, 0.4167, 0.1017, 0.0417],\n",
      "        [0.5833, 0.3333, 0.7797, 0.8750]])\n"
     ]
    }
   ],
   "source": [
    "class IrisDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = torch.tensor(data, dtype = torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "dataset = IrisDataset(X)\n",
    "dataloader = DataLoader(dataset, batch_size = 32, shuffle = True)\n",
    "\n",
    "for batch in dataloader:\n",
    "    print(f'{batch.shape}\\n{batch}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fecc5c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T10:01:02.559314Z",
     "start_time": "2024-12-09T10:01:02.555117Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in dataloader:\n",
    "    batch = i\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "370c1312",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T10:53:30.209875Z",
     "start_time": "2024-12-09T10:53:30.182218Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.1180, -1.0537],\n",
       "         [-1.2860,  0.7071],\n",
       "         [-1.2796,  0.7008],\n",
       "         [-0.1179, -1.0540],\n",
       "         [-0.1179, -1.0539],\n",
       "         [-0.1150, -0.4757],\n",
       "         [-0.1179, -1.0541],\n",
       "         [-0.1179, -1.0541],\n",
       "         [-0.2086, -0.8185],\n",
       "         [-0.1179, -1.0541],\n",
       "         [-0.2683, -0.3688],\n",
       "         [-0.1179, -1.0542],\n",
       "         [-0.1186, -1.0522],\n",
       "         [-0.1179, -1.0542],\n",
       "         [-0.1179, -1.0542],\n",
       "         [-0.5728, -0.7368],\n",
       "         [-0.1180, -1.0538],\n",
       "         [-0.1179, -1.0542],\n",
       "         [-0.1181, -1.0534],\n",
       "         [-0.1179, -1.0542],\n",
       "         [-0.1179, -1.0542],\n",
       "         [-0.1179, -1.0541],\n",
       "         [-1.2877,  0.7089],\n",
       "         [-0.1179, -1.0541],\n",
       "         [-0.1179, -1.0542],\n",
       "         [-0.1150, -0.4757],\n",
       "         [-1.2877,  0.7088],\n",
       "         [-1.2470,  0.6680],\n",
       "         [-0.1182, -1.0531],\n",
       "         [-0.1179, -1.0542],\n",
       "         [-1.2871,  0.7082],\n",
       "         [-0.1183, -1.0529]], grad_fn=<AddmmBackward0>),\n",
       " tensor([[ 1.0137,  0.7909],\n",
       "         [ 0.0635, -0.4642],\n",
       "         [ 0.0645, -0.4578],\n",
       "         [ 1.0140,  0.7910],\n",
       "         [ 1.0140,  0.7910],\n",
       "         [ 0.2650,  0.7351],\n",
       "         [ 1.0141,  0.7911],\n",
       "         [ 1.0142,  0.7911],\n",
       "         [ 0.8128,  0.6836],\n",
       "         [ 1.0141,  0.7911],\n",
       "         [ 0.3005,  0.5829],\n",
       "         [ 1.0142,  0.7911],\n",
       "         [ 1.0124,  0.7903],\n",
       "         [ 1.0142,  0.7911],\n",
       "         [ 1.0142,  0.7911],\n",
       "         [ 1.1192,  0.3395],\n",
       "         [ 1.0139,  0.7910],\n",
       "         [ 1.0142,  0.7911],\n",
       "         [ 1.0135,  0.7908],\n",
       "         [ 1.0142,  0.7911],\n",
       "         [ 1.0142,  0.7911],\n",
       "         [ 1.0141,  0.7911],\n",
       "         [ 0.0632, -0.4661],\n",
       "         [ 1.0141,  0.7911],\n",
       "         [ 1.0142,  0.7911],\n",
       "         [ 0.2650,  0.7351],\n",
       "         [ 0.0632, -0.4660],\n",
       "         [ 0.0698, -0.4244],\n",
       "         [ 1.0133,  0.7907],\n",
       "         [ 1.0142,  0.7911],\n",
       "         [ 0.0633, -0.4654],\n",
       "         [ 1.0130,  0.7906]], grad_fn=<AddmmBackward0>),\n",
       " tensor([[0.4638, 0.5134, 0.4619, 0.3953],\n",
       "         [0.5762, 0.5242, 0.4226, 0.3955],\n",
       "         [0.4212, 0.5915, 0.6483, 0.3895],\n",
       "         [0.5026, 0.5054, 0.4343, 0.3835],\n",
       "         [0.4941, 0.5959, 0.5571, 0.3319],\n",
       "         [0.5044, 0.5808, 0.6955, 0.3195],\n",
       "         [0.5098, 0.5458, 0.6425, 0.2251],\n",
       "         [0.4438, 0.5497, 0.6215, 0.3128],\n",
       "         [0.5201, 0.6154, 0.6617, 0.3439],\n",
       "         [0.5028, 0.5851, 0.7069, 0.3261],\n",
       "         [0.4771, 0.5507, 0.4859, 0.4584],\n",
       "         [0.6036, 0.3547, 0.4886, 0.5892],\n",
       "         [0.5436, 0.4803, 0.4506, 0.4925],\n",
       "         [0.4434, 0.5341, 0.5354, 0.4893],\n",
       "         [0.5637, 0.4588, 0.4767, 0.3878],\n",
       "         [0.4824, 0.5493, 0.4099, 0.4279],\n",
       "         [0.5677, 0.5593, 0.6549, 0.4175],\n",
       "         [0.4891, 0.5788, 0.7028, 0.3296],\n",
       "         [0.4744, 0.5285, 0.4998, 0.2796],\n",
       "         [0.5598, 0.6121, 0.6556, 0.3162],\n",
       "         [0.4612, 0.5807, 0.5242, 0.3232],\n",
       "         [0.5385, 0.5072, 0.6700, 0.3276],\n",
       "         [0.4808, 0.5277, 0.4808, 0.4809],\n",
       "         [0.4709, 0.5930, 0.5063, 0.4787],\n",
       "         [0.5497, 0.6487, 0.4580, 0.3621],\n",
       "         [0.4571, 0.4806, 0.3442, 0.5648],\n",
       "         [0.5023, 0.4940, 0.6402, 0.2331],\n",
       "         [0.5351, 0.6051, 0.5455, 0.3172],\n",
       "         [0.4208, 0.5583, 0.6965, 0.3468],\n",
       "         [0.5033, 0.4802, 0.4617, 0.3555],\n",
       "         [0.5756, 0.5984, 0.5769, 0.3599],\n",
       "         [0.4623, 0.4839, 0.4163, 0.4685]], grad_fn=<SigmoidBackward0>))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VariationalAutoEncoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_dim = 4, \n",
    "                 layers = 5,\n",
    "                 dropout_rate = 0.5,\n",
    "                 latent_space_dim = 2):\n",
    "        super(VariationalAutoEncoder, self).__init__()\n",
    "        \n",
    "        max_neurons = 2 ** layers\n",
    "\n",
    "        encoder_layers_list = [\n",
    "            nn.Linear(input_dim, max_neurons),\n",
    "            nn.LayerNorm(max_neurons),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        ]\n",
    "        \n",
    "        current_dim = max_neurons\n",
    "        while current_dim > latent_space_dim:\n",
    "            next_dim = current_dim // 2\n",
    "            encoder_layers_list.extend([\n",
    "                nn.Linear(current_dim, next_dim),\n",
    "                nn.LayerNorm(next_dim),\n",
    "                nn.ELU(),\n",
    "                nn.Dropout(dropout_rate)\n",
    "            ])\n",
    "            current_dim = next_dim\n",
    "        \n",
    "        #encoder_layers_list.append(nn.Linear(current_dim, latent_space_dim))\n",
    "\n",
    "        self.Encoder = nn.Sequential(*encoder_layers_list)\n",
    "        \n",
    "        self.fc_mu = nn.Linear(next_dim, latent_space_dim)\n",
    "        self.fc_logvar = nn.Linear(next_dim, latent_space_dim)\n",
    "        \n",
    "        decoder_layers_list = []\n",
    "        current_dim = latent_space_dim\n",
    "        while current_dim < max_neurons:\n",
    "            next_dim = current_dim * 2\n",
    "            decoder_layers_list.extend([\n",
    "                nn.Linear(current_dim, next_dim),\n",
    "                nn.LayerNorm(next_dim),\n",
    "                nn.ELU(),\n",
    "                nn.Dropout(dropout_rate)\n",
    "            ])\n",
    "            current_dim = next_dim\n",
    "        \n",
    "        # L'ultimo strato del decoder per ricostruire l'input\n",
    "        decoder_layers_list.append(nn.Linear(current_dim, input_dim))\n",
    "        decoder_layers_list.append(nn.Sigmoid())\n",
    "        \n",
    "        self.Decoder = nn.Sequential(*decoder_layers_list)\n",
    "        \n",
    "        \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        \"\"\"\n",
    "        Implementa il trick della rielaborazione per campionare dallo spazio latente.\n",
    "        Args:\n",
    "            mu (torch.Tensor): Media della distribuzione latente (dimensione: batch_size x latent_dim).\n",
    "            logvar (torch.Tensor): Log-varianza della distribuzione latente (dimensione: batch_size x latent_dim).\n",
    "        Returns:\n",
    "            z (torch.Tensor): Campione dallo spazio latente (dimensione: batch_size x latent_dim).\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5 * logvar)  # Calcola lo scarto quadratico medio\n",
    "        epsilon = torch.randn_like(std)  # Campiona da una distribuzione normale standard\n",
    "        z = mu + epsilon * std  # Applica il trick della rielaborazione\n",
    "        return z\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.Encoder(x)\n",
    "        mu, log_var = self.fc_mu(x), self.fc_logvar(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        reconstruction = self.Decoder(z)\n",
    "        \n",
    "        return mu, log_var, reconstruction\n",
    "        \n",
    "        \n",
    "vae = VariationalAutoEncoder(layers = 5, latent_space_dim = 2, dropout_rate = 0.1)\n",
    "vae\n",
    "vae(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b073b856",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T10:53:30.758618Z",
     "start_time": "2024-12-09T10:53:30.752045Z"
    }
   },
   "outputs": [],
   "source": [
    "lr = 1e-5\n",
    "\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    # Perdita di ricostruzione (Errore quadratico medio)\n",
    "    reconstruction_loss = F.mse_loss(recon_x, x, reduction='sum')\n",
    "    \n",
    "    # Perdita di Divergenza KL\n",
    "    # Divari di distribuzioni (appena appreso vs. normale standard)\n",
    "    # Formula di KL: -0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    # dove mu e sigma sono la media e la deviazione standard della distribuzione latente.\n",
    "    kl_divergence = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    \n",
    "    # Funzione di perdita totale\n",
    "    return reconstruction_loss + kl_divergence\n",
    "\n",
    "optimizer = optim.AdamW(vae.parameters(), lr = lr)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min = 1e-3, T_max = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d003b331",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T10:55:19.211912Z",
     "start_time": "2024-12-09T10:53:38.188012Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c4084e9bcbc4086bc6bc9f49d6a656d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/10000], Loss: 1.3016\n",
      "Epoch [200/10000], Loss: 1.2669\n",
      "Epoch [300/10000], Loss: 1.1849\n",
      "Epoch [400/10000], Loss: 1.1557\n",
      "Epoch [500/10000], Loss: 1.1340\n",
      "Epoch [600/10000], Loss: 1.1180\n",
      "Epoch [700/10000], Loss: 1.0517\n",
      "Epoch [800/10000], Loss: 1.0766\n",
      "Epoch [900/10000], Loss: 1.0208\n",
      "Epoch [1000/10000], Loss: 0.9848\n",
      "Epoch [1100/10000], Loss: 0.9674\n",
      "Epoch [1200/10000], Loss: 0.9458\n",
      "Epoch [1300/10000], Loss: 0.9213\n",
      "Epoch [1400/10000], Loss: 0.8632\n",
      "Epoch [1500/10000], Loss: 0.8451\n",
      "Epoch [1600/10000], Loss: 0.8272\n",
      "Epoch [1700/10000], Loss: 0.8006\n",
      "Epoch [1800/10000], Loss: 0.7781\n",
      "Epoch [1900/10000], Loss: 0.7684\n",
      "Epoch [2000/10000], Loss: 0.7569\n",
      "Epoch [2100/10000], Loss: 0.7158\n",
      "Epoch [2200/10000], Loss: 0.7144\n",
      "Epoch [2300/10000], Loss: 0.6812\n",
      "Epoch [2400/10000], Loss: 0.6486\n",
      "Epoch [2500/10000], Loss: 0.6271\n",
      "Epoch [2600/10000], Loss: 0.6213\n",
      "Epoch [2700/10000], Loss: 0.6020\n",
      "Epoch [2800/10000], Loss: 0.5818\n",
      "Epoch [2900/10000], Loss: 0.5708\n",
      "Epoch [3000/10000], Loss: 0.5608\n",
      "Epoch [3100/10000], Loss: 0.5530\n",
      "Epoch [3200/10000], Loss: 0.5278\n",
      "Epoch [3300/10000], Loss: 0.5015\n",
      "Epoch [3400/10000], Loss: 0.5031\n",
      "Epoch [3500/10000], Loss: 0.4854\n",
      "Epoch [3600/10000], Loss: 0.4832\n",
      "Epoch [3700/10000], Loss: 0.4715\n",
      "Epoch [3800/10000], Loss: 0.4625\n",
      "Epoch [3900/10000], Loss: 0.4309\n",
      "Epoch [4000/10000], Loss: 0.4414\n",
      "Epoch [4100/10000], Loss: 0.4333\n",
      "Epoch [4200/10000], Loss: 0.4129\n",
      "Epoch [4300/10000], Loss: 0.3923\n",
      "Epoch [4400/10000], Loss: 0.4002\n",
      "Epoch [4500/10000], Loss: 0.3944\n",
      "Epoch [4600/10000], Loss: 0.3884\n",
      "Epoch [4700/10000], Loss: 0.3816\n",
      "Epoch [4800/10000], Loss: 0.3689\n",
      "Epoch [4900/10000], Loss: 0.3644\n",
      "Epoch [5000/10000], Loss: 0.3609\n",
      "Epoch [5100/10000], Loss: 0.3574\n",
      "Epoch [5200/10000], Loss: 0.3398\n",
      "Epoch [5300/10000], Loss: 0.3471\n",
      "Epoch [5400/10000], Loss: 0.3392\n",
      "Epoch [5500/10000], Loss: 0.3371\n",
      "Epoch [5600/10000], Loss: 0.3362\n",
      "Epoch [5700/10000], Loss: 0.3254\n",
      "Epoch [5800/10000], Loss: 0.3221\n",
      "Epoch [5900/10000], Loss: 0.3243\n",
      "Epoch [6000/10000], Loss: 0.3132\n",
      "Epoch [6100/10000], Loss: 0.3169\n",
      "Epoch [6200/10000], Loss: 0.3181\n",
      "Epoch [6300/10000], Loss: 0.3050\n",
      "Epoch [6400/10000], Loss: 0.3115\n",
      "Epoch [6500/10000], Loss: 0.3051\n",
      "Epoch [6600/10000], Loss: 0.3038\n",
      "Epoch [6700/10000], Loss: 0.3045\n",
      "Epoch [6800/10000], Loss: 0.2907\n",
      "Epoch [6900/10000], Loss: 0.2954\n",
      "Epoch [7000/10000], Loss: 0.3032\n",
      "Epoch [7100/10000], Loss: 0.2957\n",
      "Epoch [7200/10000], Loss: 0.3080\n",
      "Epoch [7300/10000], Loss: 0.3013\n",
      "Epoch [7400/10000], Loss: 0.2926\n",
      "Epoch [7500/10000], Loss: 0.2967\n",
      "Epoch [7600/10000], Loss: 0.2862\n",
      "Epoch [7700/10000], Loss: 0.2926\n",
      "Epoch [7800/10000], Loss: 0.2879\n",
      "Epoch [7900/10000], Loss: 0.2890\n",
      "Epoch [8000/10000], Loss: 0.2920\n",
      "Epoch [8100/10000], Loss: 0.2933\n",
      "Epoch [8200/10000], Loss: 0.2915\n",
      "Epoch [8300/10000], Loss: 0.2877\n",
      "Epoch [8400/10000], Loss: 0.2918\n",
      "Epoch [8500/10000], Loss: 0.2850\n",
      "Epoch [8600/10000], Loss: 0.2855\n",
      "Epoch [8700/10000], Loss: 0.2817\n",
      "Epoch [8800/10000], Loss: 0.2866\n",
      "Epoch [8900/10000], Loss: 0.2806\n",
      "Epoch [9000/10000], Loss: 0.2831\n",
      "Epoch [9100/10000], Loss: 0.2813\n",
      "Epoch [9200/10000], Loss: 0.2817\n",
      "Epoch [9300/10000], Loss: 0.2799\n",
      "Epoch [9400/10000], Loss: 0.2832\n",
      "Epoch [9500/10000], Loss: 0.2831\n",
      "Epoch [9600/10000], Loss: 0.2792\n",
      "Epoch [9700/10000], Loss: 0.2786\n",
      "Epoch [9800/10000], Loss: 0.2821\n",
      "Epoch [9900/10000], Loss: 0.2792\n"
     ]
    }
   ],
   "source": [
    "epochs = 10000\n",
    "\n",
    "for epoch in tqdm(range(epochs), desc = 'Training'):\n",
    "    vae.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, data in enumerate(dataloader):\n",
    "        \n",
    "        data = data.float()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        mu, log_var, rec = vae(data)\n",
    "        loss = loss_function(rec, data, mu, log_var)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    #scheduler.step()\n",
    "        \n",
    "    avg_train_loss = train_loss / len(dataloader.dataset)\n",
    "    if epoch % 100 == 0 and epoch != 0:\n",
    "        print(f'Epoch [{epoch}/{epochs}], Loss: {avg_train_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d7eedabd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T10:15:59.357718Z",
     "start_time": "2024-12-09T10:15:59.346869Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_iris()['data'][:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5351a832",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T10:16:20.587145Z",
     "start_time": "2024-12-09T10:16:20.577926Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.86594  , 3.0473926, 3.80724  , 1.2023778],\n",
       "       [5.840497 , 3.046419 , 3.7648084, 1.1697036],\n",
       "       [5.90191  , 3.1055648, 3.7460694, 1.2322149],\n",
       "       [5.8999605, 3.052249 , 3.7557404, 1.2146475],\n",
       "       [5.8790903, 3.062522 , 3.8294742, 1.2064927],\n",
       "       [5.9214964, 3.0560744, 3.7653651, 1.1950041],\n",
       "       [5.804203 , 3.0792027, 3.8179514, 1.1977283],\n",
       "       [5.879549 , 3.0820544, 3.665507 , 1.2187321],\n",
       "       [5.884159 , 3.0740461, 3.8082573, 1.205911 ],\n",
       "       [5.903711 , 3.0609593, 3.6797545, 1.2421105],\n",
       "       [5.8490405, 3.0820832, 3.6767902, 1.2125052],\n",
       "       [5.8668733, 3.0659554, 3.7314997, 1.195871 ],\n",
       "       [5.852328 , 3.0316799, 3.8162563, 1.2233747],\n",
       "       [5.932607 , 3.0657039, 3.8027287, 1.1813002],\n",
       "       [5.8609977, 3.0715013, 3.8723722, 1.1570592],\n",
       "       [5.8390565, 3.0444613, 3.749691 , 1.2066691],\n",
       "       [5.84271  , 3.0425165, 3.7996316, 1.1879617],\n",
       "       [5.9089704, 3.0193138, 3.8356688, 1.1979198],\n",
       "       [5.8398366, 3.0700977, 3.8445954, 1.2575917],\n",
       "       [5.851189 , 3.1022239, 3.8272195, 1.2539169],\n",
       "       [5.885329 , 3.0533893, 3.819109 , 1.1765568],\n",
       "       [5.802134 , 3.1136308, 3.8413846, 1.1634448],\n",
       "       [5.9146295, 3.0705001, 3.8119597, 1.213839 ],\n",
       "       [5.833208 , 3.0768101, 3.6509798, 1.2482598],\n",
       "       [5.893298 , 3.0712252, 3.8514404, 1.2546811],\n",
       "       [5.8129015, 3.0627956, 3.7035336, 1.1920671],\n",
       "       [5.8990355, 3.0723715, 3.7433772, 1.2301614],\n",
       "       [5.907563 , 3.0818386, 3.759261 , 1.2168697],\n",
       "       [5.903593 , 3.0931664, 3.693727 , 1.2156959],\n",
       "       [5.865805 , 3.0637863, 3.7728722, 1.1964136],\n",
       "       [5.802252 , 3.0171258, 3.8739994, 1.220829 ],\n",
       "       [5.9029264, 3.0464597, 3.7497594, 1.2001584]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_max.inverse_transform(vae(torch.randn(32,4))[2].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a65467",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
